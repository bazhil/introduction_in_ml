{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2ad945",
   "metadata": {},
   "source": [
    "# SVM Support Vector Machine (Метод опорных векторов)\n",
    "\n",
    "Применение алгоритма SVM для решения задачи классификации.\n",
    "\n",
    "\n",
    "### Датасет\n",
    "Рассматривать задачу будем на примере известного датасета **Цветки Ириса**\n",
    "\n",
    "Датасет [Цветки Ириса](https://archive.ics.uci.edu/ml/datasets/iris) содержит 150 записей, каждая из записей содержит 4 признака, т.е. $\\boldsymbol x \\in \\mathbb{R}^4$. \n",
    "\n",
    "Что за 4 признака?\n",
    "\n",
    "0. длина чашелистника, см\n",
    "1. ширина чашелистника, см\n",
    "2. длина лепестка, см \n",
    "3. ширина лепестка, см \n",
    "\n",
    "Метки классов\n",
    "\n",
    "0. Setosa\n",
    "1. Versicolour \n",
    "2. Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a0337",
   "metadata": {},
   "source": [
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e702307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# программная реализация алгоритма SVM для классификации\n",
    "from sklearn.svm import SVC\n",
    "# программная реализация расчета метрики точности\n",
    "from sklearn.metrics import accuracy_score\n",
    "# модуль для разделения выборки на тестовую и обучающую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# модуль, позволяющий подтягивать данные по хрестоматийным примерам для ML\n",
    "from sklearn import datasets\n",
    "\n",
    "# модули визуализации данных\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Библиотеки для работы с векторами и таблицыми данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Модуль для нормализации данных\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5ea96",
   "metadata": {},
   "source": [
    "## 1. Загружаем данные по цветкам ирисов\n",
    "\n",
    "Для этого воспользуемся встроенным в библиотеке scikit-learn модулем datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f791c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ed262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Информация по признакам\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация по целевой переменной (классам цветка)\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a087f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем информацию по размерности датасета и целевой переменной\n",
    "# чтобы убедиться, что размерности совпадают\n",
    "print('Размерность признакового пространства {}'.format(iris.data.shape))\n",
    "print('Размерность вектора целевой переменной {}'.format(iris.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вынесем признаки и целевую перемнную в отдельные переменные\n",
    "X = iris.data[:, :4] \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c958e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посмотрим на гистограмму распределения целевой переменной\n",
    "sns.histplot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c0ffc",
   "metadata": {},
   "source": [
    "Данные очень хорошо сбалансированы - каждого класса по 50 объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим dataframe на основании исходных данных\n",
    "# для простоты отображения графиков\n",
    "iris_df = pd.DataFrame(np.c_[iris.data, iris.target], columns=['sepal length (cm)', \n",
    "                                                               'sepal width (cm)', \n",
    "                                                               'petal length (cm)',\n",
    "                                                               'petal width (cm)',\n",
    "                                                               'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c07447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# При помощи модуля seaborn.pairplot визуализируем попарные зависимости данных\n",
    "# На основной диагонали показаные гистограммы распределения параметров\n",
    "sns.pairplot(iris_df,hue='class',palette='Dark2');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599a70e",
   "metadata": {},
   "source": [
    "# 2. Обучение модели\n",
    "\n",
    "Прежде чем приступить к обучению модели, предварительно создадим функцию, которая будет визуализировать границы классов на основании обученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3bd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(X_train, X_test, y_test, model):\n",
    "    h = .02  # шаг сетки\n",
    "    # Создадим сетку для отображения\n",
    "    x_min, x_max = X_test[:, 0].min()*0.9, X_test[:, 0].max()*1.1\n",
    "    y_min, y_max = X_test[:, 1].min()*0.9, X_test[:, 1].max()*1.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "    \n",
    "    y_pred = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # \"Восстановим\" прогнозные точки на новой сетке\n",
    "    y_pred = y_pred.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.seismic, alpha=0.8)\n",
    "\n",
    "    # Добавим на график точки из датасета\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.seismic)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "def print_acc(y_test, y_pred, text):\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(text + str(round(accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb43a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.drop('class', axis=1)  \n",
    "y = iris_df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20659885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM с параметрами по умолчанию\n",
    "classifier_SVM = SVC()\n",
    "\n",
    "# Обучение модели\n",
    "classifier_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Прогноз\n",
    "y_pred = classifier_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d71fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "print_acc(y_test, y_pred, 'Точность на тестовой выборке ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28882d32",
   "metadata": {},
   "source": [
    "## 2.1. Параметры SVM\n",
    "### Ядро\n",
    "\n",
    "**Линейное ядро**\n",
    "\n",
    "Линейные ядра вычисляют близость во входном пространстве. Они неявно определяют трансформацию в измерения более высоких порядков. Из-за этого каждая из гиперплоскостей на рисунке выше представляет собой прямые линии.\n",
    "\n",
    "Линейное ядро определяется как $\\langle x,x' \\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be44b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vis = X[['sepal length (cm)', 'sepal width (cm)']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vis, y, test_size = 0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d996aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM c линейным ядром\n",
    "SVM_linear = SVC(kernel='linear')\n",
    "\n",
    "# Обучение модели\n",
    "SVM_linear.fit(X_train, y_train);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "y_pred = SVM_linear.predict(X_test)\n",
    "print_acc(y_test, y_pred, 'Линейное ядро. Точность на тестовой выборке ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d84c4b",
   "metadata": {},
   "source": [
    "**Полиномиальное ядро**\n",
    "\n",
    "Линейное ядро - частный случай полиномиального, когда степень = 1.\n",
    "\n",
    "Полиномиальное ядро определяется как $(\\gamma\\langle x,x' + r \\rangle)^d$, где где $d$ указывается параметром `degree`, $r$ при помощи `coef0`.\n",
    "\n",
    "Ядро полинома позволяет нам искать нелинейные паттерны в наших данных, как если бы у нас был доступ к функциям взаимодействия, которые являются результатом объединения ранее существующих функций ($a^2, b^2, ab$ и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM c полиномиальным ядром и степенью полинома 3\n",
    "SVM_poly = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Обучение модели\n",
    "SVM_poly.fit(X_train, y_train);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9977c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "y_pred = SVM_poly.predict(X_test)\n",
    "print_acc(y_test, y_pred, 'Полиномиальное ядро. Точность на тестовой выборке ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f6eb0",
   "metadata": {},
   "source": [
    "**Сигмовидное ядро**\n",
    "\n",
    "Ядро определяется как $tanh(\\gamma\\langle x,x'\\rangle+r)$, где $r$ указывается как `coef0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaaf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM c сигмовидным ядром\n",
    "SVM_sigmoid = SVC(kernel='sigmoid', gamma=\"auto\")\n",
    "\n",
    "# Обучение модели\n",
    "SVM_sigmoid.fit(X_train, y_train);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "y_pred = SVM_sigmoid.predict(X_test)\n",
    "print_acc(y_test, y_pred, 'Сигмоидальное ядро. Точность на тестовой выборке ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length_norm = normalize(X.values[:,0].reshape(1, -1))[0] \n",
    "sepal_width_norm = normalize(X.values[:,1].reshape(1, -1))[0]\n",
    "\n",
    "# Создадим объект класса SVM c сигмоидальным ядром\n",
    "SVM_sigmoid_norm = SVC(kernel='sigmoid', gamma=\"auto\")\n",
    "\n",
    "# Обучение модели\n",
    "SVM_sigmoid_norm.fit(np.c_[sepal_length_norm, sepal_width_norm], y);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(np.c_[sepal_length_norm, sepal_width_norm], np.c_[sepal_length_norm, sepal_width_norm], y.values, SVM_sigmoid_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddaf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "y_pred = SVM_sigmoid_norm.predict(np.c_[sepal_length_norm, sepal_width_norm])\n",
    "print_acc(y, y_pred, 'Сигмоидальное ядро. Точность на полной выборке ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d9141",
   "metadata": {},
   "source": [
    "**Радиальная базисная функция**\n",
    "\n",
    "Ядро выглядит как $exp(-\\gamma|x-x'|^2)$, где $\\gamma$ указывается параметром `gamma`, должно быть строго больше 0.\n",
    "\n",
    "При обучении `SVM` с ядром Радиальной Базовой Функции (Radial Basis Function — RBF) необходимо учитывать два параметра: `C` и gamma. Параметр `C`, общий для всех ядер `SVM`, компенсирует неправильную классификацию обучающих примеров простотой поверхности принятия решений. Низкое значение `C` делает поверхность принятия решения гладкой, а высокое `C` правильные классификации всех обучающих примеров. gamma определяет, какое влияние имеет один обучающий пример. Чем больше `gamma`, тем ближе другие примеры должны быть затронуты.\n",
    "\n",
    "Правильный выбор `C` и `gamma` имеет решающее значение для производительности SVM. Рекомендуется использовать `GridSearchCV` с `C` и `gamma` экспоненциально далеко друг от друга, чтобы выбрать хорошие значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ed8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM c РБФ ядром\n",
    "SVM_RBF = SVC(kernel='rbf')\n",
    "\n",
    "# Обучение модели\n",
    "SVM_RBF.fit(X_train, y_train);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем точность модели как долю верно классифицированных объектов\n",
    "y_pred = SVM_RBF.predict(X_test)\n",
    "print_acc(y_test, y_pred, 'РБФ ядро. Точность на тестовой выборке ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfa8d1",
   "metadata": {},
   "source": [
    "### C: параметр штрафа\n",
    "\n",
    "Как мы уже и проговорили, параметр `C` компенсирует неправильную классификацию обучающих примеров простотой поверхности принятия решений. Давайте посмотрим как будут выглядеть разделяющие гиперплоскости при разных значениях C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса SVM c линейным ядром и C=1000000\n",
    "SVM_C_v1 = SVC(kernel='rbf', C=100000) \n",
    "# Обучение модели\n",
    "SVM_C_v1.fit(X_train, y_train);\n",
    "\n",
    "# Создадим объект класса SVM c линейным ядром и C=0.1\n",
    "SVM_C_v2 = SVC(kernel='rbf', C=0.1) \n",
    "# Обучение модели\n",
    "SVM_C_v2.fit(X_train, y_train);\n",
    "\n",
    "# Выведем границы классов по модели\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_C_v1)\n",
    "plot_contours(X_train.values, X_test.values, y_test.values, SVM_C_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0cff0",
   "metadata": {},
   "source": [
    "> # Задание\n",
    "\n",
    "> При помощи перебора параметров найти наиболее оптимальные гиперпараметры модели и посчитать метрики. Обучать модель необходимо на всем датасете (X,y) без разделения на train/test. Для выполнения задания необходимо воспользоваться модуем GridSearchCV, ниже краткое описание.\n",
    "Диапазоны параметров: ядра из множества (linear', 'poly', 'rbf'), параметр C (0.001, 0.01, 0.1, 1, 10), параметр gamma (0.01, 0.1, 0.5, 1), random state = 21. Для расчета метрики точности можно вызвать функцию `score` объекта `GridSearchCV`. Для вывода параметров наилучшей модели, можно воспользоваться функцией `best_estimator_` объекта `GridSearchCV`\n",
    "\n",
    "\n",
    "### GridSearchCV\n",
    "\n",
    "У каждого из алгоритмов есть определенный набор параметров, которые необходимо подобрать в процессе обучения модели. Но как оптимальнее всего автоматизировать этот процесс? Первое, что приходит в голову, это использовать циклы, внутри которых будем перебирать различные параметры модели. Но каждый раз описывать эти циклы довольно рутинно и неинтересно. Именно поэтому в библиотеке `Scikit-Learn` рализован инструмент перебора параметров, который называется `GridSearchCV`.\n",
    "`GridSearchCV` – это очень мощный инструмент для автоматического подбора параметров для моделей машинного обучения. `GridSearchCV` находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Также есть `RandomSearchCV` - это когда мы перебираем не по полной сетке возможных комбинаций параметров, а случайным образом выбираем комбинации и обучаем модели на них. Магические буквы `CV` - это кросс-валидация, пока параметр, отвечающий за этот функционал мы просто оставим равным 3, далее в лекциях поговорим что это такое и как с этим работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт нужного модуля\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# задаем словарь параметров для модели SVM, которые мы хотим варьироать в рамках\n",
    "# работы GridSearchCV\n",
    "parameters = {\n",
    "    'kernel':,\n",
    "    'C':,\n",
    "    'gamma':\n",
    "}\n",
    "\n",
    "# создать объект класса SVC (Support Vector Classifier) c random_state=21\n",
    "\n",
    "# создаем объект GridSearchCV с созданной моделью и param_grid с параметрами, которые задали ранее. Параметр cv=3\n",
    "\n",
    "# обучаем модель (для объекта GridSearchCV вызываем метод fit для всех исходных данных)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите метрику точности для обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите параметры наилучшей модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
